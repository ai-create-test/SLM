# ğŸ§  LLM Experimental Framework

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

ä¸€ä¸ªå®éªŒæ€§çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¼€å‘æ¡†æ¶ï¼Œä¸“æ³¨äºæ¨¡å—åŒ–æ¶æ„è®¾è®¡å’Œå‰æ²¿æŠ€æœ¯å®ç°ã€‚
å¤‡æ³¨ï¼šæœ¬é¡¹ç›®å®Œå…¨ä½¿ç”¨Google Antigravityå®Œæˆï¼Œæ²¡æœ‰ä»»ä½•äººå·¥ä»‹å…¥ã€‚

## ğŸ“– é¡¹ç›®èƒŒæ™¯

### è®¾è®¡åŠ¨æœº

æœ¬é¡¹ç›®æ—¨åœ¨æ„å»ºä¸€ä¸ª**é«˜åº¦æ¨¡å—åŒ–ã€å¯æ‰©å±•**çš„ LLM å®éªŒå¹³å°ï¼Œç”¨äºæ¢ç´¢å’ŒéªŒè¯ä»¥ä¸‹æ ¸å¿ƒæŠ€æœ¯ï¼š

1. **é—®é¢˜å¯¼å‘æ£€ç´¢ï¼ˆQuery-Focused Retrievalï¼‰** - ä»¥ç”¨æˆ·é—®é¢˜ä¸ºä¸»å¯¼çš„å¢å¼ºæ£€ç´¢é˜…è§ˆæ–¹å¼
2. **æƒ…æ„Ÿä¸åœºæ™¯æ³¨å…¥ï¼ˆContext Injectionï¼‰** - é€šè¿‡å¯å­¦ä¹ é—¨æ§æœºåˆ¶å°†æƒ…æ„Ÿ/åœºæ™¯ä¿¡æ¯èå…¥è¯­ä¹‰è¡¨ç¤º
3. **é•¿æ–‡æœ¬å¤„ç†ï¼ˆLong-Text Processingï¼‰** - è¯­ä¹‰å®Œæ•´çš„åˆ†å—ç­–ç•¥ä¸å‹ç¼©æœºåˆ¶

### æŠ€æœ¯é€‰å‹

| ç»„ä»¶ | æŠ€æœ¯æ–¹æ¡ˆ | è¯´æ˜ |
|------|----------|------|
| åˆ†è¯å™¨ | tiktoken (BPE) | OpenAI ç”Ÿäº§çº§å®ç°ï¼Œæ”¯æŒ GPT-4 ç¼–ç  |
| ä½ç½®ç¼–ç  | RoPE | æ—‹è½¬ä½ç½®ç¼–ç ï¼Œæ›´å¥½çš„é•¿åº¦å¤–æ¨èƒ½åŠ› |
| å½’ä¸€åŒ– | RMSNorm | æ¯” LayerNorm æ›´é«˜æ•ˆï¼Œè¢« LLaMA é‡‡ç”¨ |
| æ³¨æ„åŠ›æƒé‡ | BM25 / TF-IDF | å·¥ä¸šçº§æ£€ç´¢ç®—æ³• |

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Main Entry                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         app/                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¤
â”‚   core/     â”‚   memory/   â”‚ retrieval/  â”‚ reflection/ â”‚... â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚    â”‚
â”‚ â€¢ Tokenizer â”‚ â€¢ Embedding â”‚ â€¢ RAG       â”‚ â€¢ Self-     â”‚    â”‚
â”‚ â€¢ BPE       â”‚ â€¢ RoPE      â”‚ â€¢ Query-    â”‚   Reflectionâ”‚    â”‚
â”‚ â€¢ Attention â”‚ â€¢ Chunking  â”‚   Focused   â”‚             â”‚    â”‚
â”‚   Weights   â”‚ â€¢ Fusion    â”‚             â”‚             â”‚    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”˜
```

## âœ¨ æ ¸å¿ƒç‰¹æ€§

### 1. æ ¸å¿ƒåˆ†è¯æ¨¡å— (`app/core/`)

- **BPETokenizer**: åŸºäº tiktoken çš„å·¥ä¸šçº§ BPE åˆ†è¯å™¨
- **é—®é¢˜å¯¼å‘æ³¨æ„åŠ›**: æ”¯æŒ BM25ã€TF-IDFã€å…³é”®è¯åŒ¹é…ç­‰å¤šç§ç­–ç•¥
- **å·¥å‚æ¨¡å¼**: ç»Ÿä¸€çš„åˆ†è¯å™¨åˆ›å»ºæ¥å£ï¼Œæ”¯æŒåŠ¨æ€æ³¨å†Œ

```python
from app.core import get_tokenizer

# ä½¿ç”¨ GPT-4 ç¼–ç 
tokenizer = get_tokenizer("gpt4")
result = tokenizer.encode("Hello, world!", query="greeting")
print(result.attention_weights)  # é—®é¢˜å¯¼å‘æ³¨æ„åŠ›æƒé‡
```

### 2. è®°å¿†æ¨¡å— (`app/memory/`)

- **TokenEmbedding**: Token â†’ ç¨ å¯†å‘é‡è½¬æ¢
- **RoPE**: æ—‹è½¬ä½ç½®ç¼–ç ï¼Œæ”¯æŒé•¿åº¦å¤–æ¨
- **TextChunker**: è¯­ä¹‰æ„ŸçŸ¥çš„æ–‡æœ¬åˆ†å—
- **ContextFusion**: æƒ…æ„Ÿ/åœºæ™¯å¯å­¦ä¹ é—¨æ§æ³¨å…¥

```python
from app.memory import create_context_aware_embedding, EMOTION_IDS

# åˆ›å»ºä¸Šä¸‹æ–‡æ„ŸçŸ¥åµŒå…¥å±‚
embedding = create_context_aware_embedding(preset='base')

# æ³¨å…¥æƒ…æ„Ÿ
import torch
token_ids = torch.tensor([[100, 200, 300]])
output = embedding(token_ids, emotion_id=EMOTION_IDS["happy"])
```

### 3. é•¿æ–‡æœ¬ç¼–ç å™¨ (`app/memory/MemoryEncoder`)

```python
from app.memory import create_memory_encoder

encoder = create_memory_encoder(preset='base')
result = encoder.encode_with_chunks("éå¸¸é•¿çš„æ–‡æœ¬...")

print(f"åˆ†å—æ•°: {result.num_chunks}")
print(f"åµŒå…¥å½¢çŠ¶: {result.embeddings.shape}")  # [chunks, seq_len, d_model]
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
gemini_test/
â”œâ”€â”€ main.py                 # å…¥å£æ–‡ä»¶
â”œâ”€â”€ requirements.txt        # ä¾èµ–æ¸…å•
â”œâ”€â”€ README.md              # é¡¹ç›®æ–‡æ¡£
â”œâ”€â”€ .gitignore             # Git å¿½ç•¥è§„åˆ™
â”‚
â”œâ”€â”€ app/                   # æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
â”‚   â”œâ”€â”€ core/              # åˆ†è¯å™¨ä¸æ³¨æ„åŠ›æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ tokenizer_base.py      # æŠ½è±¡åŸºç±»
â”‚   â”‚   â”œâ”€â”€ bpe_tokenizer.py       # BPE å®ç°
â”‚   â”‚   â”œâ”€â”€ tokenizer_attention.py # é—®é¢˜å¯¼å‘æ³¨æ„åŠ›
â”‚   â”‚   â””â”€â”€ tokenizer_factory.py   # å·¥å‚æ¨¡å¼
â”‚   â”‚
â”‚   â”œâ”€â”€ memory/            # åµŒå…¥ä¸è®°å¿†æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ embeddings.py     # TokenåµŒå…¥ + RoPE
â”‚   â”‚   â”œâ”€â”€ text_chunker.py   # æ–‡æœ¬åˆ†å—
â”‚   â”‚   â”œâ”€â”€ fusion.py         # æƒ…æ„Ÿ/åœºæ™¯èåˆ
â”‚   â”‚   â””â”€â”€ memory_encoder.py # æ•´åˆç¼–ç å™¨
â”‚   â”‚
â”‚   â”œâ”€â”€ retrieval/         # é—®é¢˜å¯¼å‘æ£€ç´¢ (å¾…å®ç°)
â”‚   â”œâ”€â”€ reflection/        # è‡ªæˆ‘å›æº¯ (å¾…å®ç°)
â”‚   â”œâ”€â”€ search/            # è”ç½‘æœç´¢ (å¾…å®ç°)
â”‚   â””â”€â”€ utils/             # å·¥å…·å‡½æ•° (å¾…å®ç°)
â”‚
â”œâ”€â”€ tests/                 # å•å…ƒæµ‹è¯•
â”‚   â””â”€â”€ test_tokenizer.py  # åˆ†è¯å™¨æµ‹è¯•
â”‚
â”œâ”€â”€ test_memory.py         # Memory æ¨¡å—éªŒæ”¶æµ‹è¯•
â””â”€â”€ test_fusion.py         # Context Fusion éªŒæ”¶æµ‹è¯•
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- Python 3.8+
- PyTorch 2.0+

### å®‰è£…

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/your-username/gemini_test.git
cd gemini_test

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### è¿è¡Œæµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰ pytest æµ‹è¯•
pytest tests/ -v

# è¿è¡ŒéªŒæ”¶æµ‹è¯•
python test_memory.py
python test_fusion.py
```

## ğŸ“Š å¼€å‘çŠ¶æ€

| æ¨¡å— | çŠ¶æ€ | è¯´æ˜ |
|------|------|------|
| `core/tokenizer` | âœ… å®Œæˆ | BPE åˆ†è¯å™¨ + é—®é¢˜å¯¼å‘æ³¨æ„åŠ› |
| `memory/embeddings` | âœ… å®Œæˆ | Token åµŒå…¥ + RoPE ä½ç½®ç¼–ç  |
| `memory/chunker` | âœ… å®Œæˆ | è¯­ä¹‰æ„ŸçŸ¥æ–‡æœ¬åˆ†å— |
| `memory/fusion` | âœ… å®Œæˆ | æƒ…æ„Ÿ/åœºæ™¯é—¨æ§æ³¨å…¥ |
| `retrieval/` | ğŸš§ è§„åˆ’ä¸­ | é—®é¢˜å¯¼å‘å¢å¼ºæ£€ç´¢ |
| `reflection/` | ğŸš§ è§„åˆ’ä¸­ | æ¨¡å‹è‡ªæˆ‘å›æº¯è®¾è®¡ |
| `search/` | ğŸš§ è§„åˆ’ä¸­ | å®æ—¶ç½‘ç»œæœç´¢ |

## ğŸ”§ é…ç½®é€‰é¡¹

### é¢„è®¾é…ç½®

| é¢„è®¾ | vocab_size | d_model | max_seq_len |
|------|------------|---------|-------------|
| small | 110,000 | 256 | 256 |
| base | 110,000 | 768 | 512 |
| large | 150,000 | 1024 | 1024 |

### è‡ªå®šä¹‰é…ç½®

```python
from app.memory import MemoryEncoder

encoder = MemoryEncoder(
    vocab_size=100000,
    d_model=512,
    max_seq_len=1024,
    position_encoding='rope',
    dropout=0.1,
)
```

## ğŸ“ API å‚è€ƒ

### ä¸»è¦ç±»

| ç±»å | æ¨¡å— | è¯´æ˜ |
|------|------|------|
| `BPETokenizer` | `app.core` | BPE åˆ†è¯å™¨ |
| `TokenizerFactory` | `app.core` | åˆ†è¯å™¨å·¥å‚ |
| `CombinedEmbedding` | `app.memory` | ç»„åˆåµŒå…¥å±‚ |
| `ContextAwareEmbedding` | `app.memory` | ä¸Šä¸‹æ–‡æ„ŸçŸ¥åµŒå…¥ |
| `MemoryEncoder` | `app.memory` | æ•´åˆç¼–ç å™¨ |
| `TextChunker` | `app.memory` | æ–‡æœ¬åˆ†å—å™¨ |

### ä¾¿æ·å‡½æ•°

```python
from app.core import get_tokenizer
from app.memory import create_memory_encoder, create_context_aware_embedding
```

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“„ License

MIT License - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶
